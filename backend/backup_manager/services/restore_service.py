"""
Service de restauration pour les sauvegardes
"""

import zipfile
import tempfile
import subprocess
import shutil
import re
import sqlite3
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from django.conf import settings
from django.utils import timezone
from ..models import BackupHistory, RestoreHistory
from .base_service import BaseService
from .metadata_service import MetadataService
from .storage_service import StorageService
from .encryption_service import EncryptionService


class RestoreError(Exception):
    """Exception spÃ©cifique pour les erreurs de restauration"""
    pass


class DatabaseRestoreError(RestoreError):
    """Exception spÃ©cifique pour les erreurs de restauration de base de donnÃ©es"""
    pass


class FileRestoreError(RestoreError):
    """Exception spÃ©cifique pour les erreurs de restauration de fichiers"""
    pass


class RestoreService(BaseService):
    """Service pour restaurer les sauvegardes"""
    
    # Constantes
    DATABASE_DUMP_FILENAME = "database.sql"
    DATABASE_SQLITE_FILENAME = "database.sqlite3"
    METADATA_FILENAME = "metadata.json"
    FILES_DIRNAME = "files"
    
    AUTO_CLEANUP_MAX_AGE_HOURS = 2
    MAX_SQL_RETRIES = 3
    
    # Valeurs par dÃ©faut pour corrections NOT NULL
    DEFAULT_NOT_NULL_VALUES = {
        'encryption_enabled': 'TRUE',
        'compression_enabled': 'TRUE', 
        'encryption_algorithm': "'AES256'",
        'compression_level': '6',
        'created_at': "datetime('now')",
        'updated_at': "datetime('now')",
    }
    
    def __init__(self):
        super().__init__('RestoreService')
        self.metadata_service = MetadataService()
        self.storage_service = StorageService()
        self.encryption_service = EncryptionService()
    
    def restore_backup(self, backup: BackupHistory, user, restore_options: Optional[Dict[str, Any]] = None) -> RestoreHistory:
        """
        Restaure une sauvegarde
        
        Args:
            backup: Sauvegarde Ã  restaurer
            user: Utilisateur qui lance la restauration
            restore_options: Options de restauration
            
        Returns:
            Instance RestoreHistory crÃ©Ã©e
        """
        restore_options = restore_options or {}
        restore_history = self._create_restore_history(backup, user, restore_options)
        
        try:
            self._execute_restore_workflow(backup, user, restore_options, restore_history)
            return restore_history
            
        except Exception as e:
            self._handle_restore_failure(restore_history, e)
            raise
    
    def _create_restore_history(self, backup: BackupHistory, user, restore_options: Dict[str, Any]) -> RestoreHistory:
        """CrÃ©e l'enregistrement d'historique de restauration"""
        restore_name = f"Restauration_{backup.backup_name}_{timezone.now().strftime('%Y%m%d_%H%M%S')}"
        restore_type = restore_options.get('restore_type', 'full')
        
        return RestoreHistory.objects.create(
            backup_source=backup,
            restore_name=restore_name,
            restore_type=restore_type,
            status='running',
            restore_options=restore_options,
            started_at=timezone.now(),
            created_by=user
        )
    
    def _execute_restore_workflow(self, backup: BackupHistory, user, restore_options: Dict[str, Any], restore_history: RestoreHistory) -> None:
        """ExÃ©cute le workflow complet de restauration"""
        self.start_operation(f"Restauration {restore_history.restore_name}")
        
        # PrÃ©paration des fichiers
        work_dir, extract_dir = self._prepare_restore_files(backup, user, restore_history.restore_name)
        
        try:
            # S'assurer que le statut est bien 'running'
            restore_history.status = 'running'
            restore_history.save(update_fields=['status'])
            self.log_info(f"ğŸš€ Statut de restauration mis Ã  jour: running (ID: {restore_history.id})")
            
            # ExÃ©cution des phases de restauration
            stats = self._execute_restore_phases(extract_dir, restore_options, restore_history)
            
            # Finalisation
            self._finalize_restore(restore_history, stats)
            
            # Nettoyage
            self._cleanup_after_restore(work_dir)
            
        except Exception as e:
            self.log_error(f"âŒ Erreur pendant la restauration: {str(e)}", e)
            self._handle_restore_failure(restore_history, e)
            self._cleanup_after_restore(work_dir)
            raise
    
    def _prepare_restore_files(self, backup: BackupHistory, user, restore_name: str) -> Tuple[Path, Path]:
        """PrÃ©pare les fichiers nÃ©cessaires Ã  la restauration"""
        # RÃ©cupÃ©ration du fichier de sauvegarde
        backup_file = self.storage_service.get_backup_file(backup.file_path)
        if not backup_file:
            raise FileNotFoundError(f"Fichier de sauvegarde introuvable: {backup.file_path}")
        
        # VÃ©rifier que le fichier est bien un fichier et pas un rÃ©pertoire
        if not backup_file.is_file():
            raise FileRestoreError(f"Le chemin de sauvegarde n'est pas un fichier valide: {backup_file} (type: {type(backup_file).__name__})")
        
        # CrÃ©ation du rÃ©pertoire de travail
        work_dir = self._create_restore_directory(restore_name)
        self.log_info(f"ğŸ“ RÃ©pertoire de restauration: {work_dir}")
        
        # DÃ©chiffrement automatique si nÃ©cessaire
        source_file = self._handle_decryption_if_needed(backup_file, work_dir, user)
        
        # VÃ©rifier Ã  nouveau que le fichier source est valide aprÃ¨s dÃ©chiffrement Ã©ventuel
        if not source_file.is_file():
            raise FileRestoreError(f"Le fichier source n'est pas valide aprÃ¨s dÃ©chiffrement: {source_file}")
        
        # Extraction de l'archive
        extract_dir = self._extract_backup_archive(source_file, work_dir)
        
        return work_dir, extract_dir
    
    def _handle_decryption_if_needed(self, backup_file: Path, work_dir: Path, user) -> Path:
        """GÃ¨re le dÃ©chiffrement du fichier si nÃ©cessaire"""
        if backup_file.suffix != '.encrypted':
            return backup_file
        
        decrypted_file = work_dir / "backup_decrypted.zip"
        system_key = self.encryption_service.generate_system_key(user)
        self.encryption_service.decrypt_file_with_key(backup_file, decrypted_file, system_key)
        self.log_info("ğŸ”“ Fichier dÃ©chiffrÃ© automatiquement avec la clÃ© systÃ¨me")
        
        return decrypted_file
    
    def _extract_backup_archive(self, archive_path: Path, work_dir: Path) -> Path:
        """Extrait l'archive de sauvegarde"""
        self.log_info("ğŸ“¦ Extraction de l'archive")
        
        extract_dir = work_dir / "extracted"
        extract_dir.mkdir(exist_ok=True)
        
        try:
            with zipfile.ZipFile(archive_path, 'r') as archive:
                # VÃ©rifier le contenu de l'archive avant extraction
                file_list = archive.namelist()
                self.log_info(f"ğŸ“‹ Archive contient {len(file_list)} fichiers/dossiers")
                
                # Extraire de maniÃ¨re sÃ©curisÃ©e en vÃ©rifiant les chemins
                for file_path in file_list:
                    # VÃ©rifier si le chemin est sÃ©curisÃ© (pas de chemin absolu ou de remontÃ©e de rÃ©pertoire)
                    if file_path.startswith('/') or '..' in file_path:
                        self.log_warning(f"âš ï¸ Chemin non sÃ©curisÃ© ignorÃ©: {file_path}")
                        continue
                    
                    # Extraire le fichier avec son chemin relatif
                    target_path = extract_dir / file_path
                    
                    # CrÃ©er le rÃ©pertoire parent si nÃ©cessaire
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Si c'est un rÃ©pertoire, juste crÃ©er le dossier
                    if file_path.endswith('/'):
                        target_path.mkdir(parents=True, exist_ok=True)
                        continue
                    
                    # Extraire le fichier
                    with archive.open(file_path) as source, open(target_path, 'wb') as target:
                        shutil.copyfileobj(source, target)
            
            self.log_info(f"âœ… Archive extraite: {extract_dir}")
            return extract_dir
            
        except zipfile.BadZipFile as e:
            raise FileRestoreError(f"Archive corrompue: {e}")
        except Exception as e:
            raise FileRestoreError(f"Erreur lors de l'extraction: {e}")
    
    def _execute_restore_phases(self, extract_dir: Path, restore_options: Dict[str, Any], restore_history: RestoreHistory) -> Dict[str, Any]:
        """ExÃ©cute les diffÃ©rentes phases de restauration"""
        restore_type = restore_options.get('restore_type', 'full')
        stats = {
            'tables_restored': 0,
            'records_restored': 0,
            'files_restored': 0
        }
        
        # Sauvegarder l'Ã©tat original de la sauvegarde source pour vÃ©rification ultÃ©rieure
        backup_source = restore_history.backup_source
        original_status = backup_source.status
        original_file_path = backup_source.file_path
        original_file_size = backup_source.file_size
        original_checksum = backup_source.checksum
        original_completed_at = backup_source.completed_at
        original_duration_seconds = backup_source.duration_seconds
        self.log_info(f"ğŸ“Š Ã‰tat initial de la sauvegarde source (ID: {backup_source.id}): {original_status}")
        
        # Phase 1: Restauration des mÃ©tadonnÃ©es
        if restore_type in ['full', 'metadata'] and (extract_dir / self.METADATA_FILENAME).exists():
            metadata_stats = self._restore_metadata(extract_dir, restore_options)
            stats.update(metadata_stats)
        
        # Phase 2: Restauration des donnÃ©es SQL
        if restore_type in ['full', 'data']:
            data_stats = self._restore_database_data(extract_dir, restore_options)
            stats.update(data_stats)
            
            # Gestion spÃ©ciale si la base a Ã©tÃ© remplacÃ©e
            if data_stats.get('database_replaced', False):
                restore_history = self._handle_database_replacement(restore_history, restore_options)
        
        # Phase 3: Restauration des fichiers
        if restore_type == 'full' and (extract_dir / self.FILES_DIRNAME).exists():
            files_stats = self._restore_files(extract_dir, restore_options)
            stats['files_restored'] = files_stats.get('files_restored', 0)
        
        # PROTECTION RENFORCÃ‰E: VÃ©rifier et protÃ©ger la sauvegarde source
        # Cette vÃ©rification est critique pour les uploads car le SQL peut contenir
        # l'ancienne version avec statut 'running' au lieu de 'completed'
        try:
            # Recharger la sauvegarde source depuis la base de donnÃ©es
            refreshed_backup = BackupHistory.objects.get(id=backup_source.id)
            metadata_changed = (
                refreshed_backup.status != original_status or
                refreshed_backup.file_path != original_file_path or
                refreshed_backup.file_size != original_file_size or
                refreshed_backup.checksum != original_checksum or
                refreshed_backup.completed_at != original_completed_at
            )
            
            # PROTECTION SPÃ‰CIALE POUR LES UPLOADS
            is_upload = restore_options.get('upload_source', False)
            if is_upload and refreshed_backup.status == 'running' and original_status == 'completed':
                self.log_warning(f"ğŸ›¡ï¸ UPLOAD DÃ‰TECTÃ‰ - Protection sauvegarde source ID {backup_source.id}")
                self.log_warning(f"ğŸ›¡ï¸ Statut restaurÃ© forcÃ©ment: 'running' -> 'completed'")
                print(f"ğŸ›¡ï¸ PROTECTION UPLOAD - Sauvegarde source {backup_source.id} forcÃ©e Ã  'completed'")
                metadata_changed = True
            
            if metadata_changed:
                if is_upload:
                    self.log_warning(f"ğŸ›¡ï¸ UPLOAD - La sauvegarde source (ID: {backup_source.id}) protÃ©gÃ©e contre la modification")
                else:
                    self.log_warning(f"âš ï¸ La sauvegarde source (ID: {backup_source.id}) a Ã©tÃ© modifiÃ©e pendant la restauration")
                
                # Restaurer TOUTES les mÃ©tadonnÃ©es originales
                refreshed_backup.status = original_status
                refreshed_backup.file_path = original_file_path
                refreshed_backup.file_size = original_file_size
                refreshed_backup.checksum = original_checksum
                refreshed_backup.completed_at = original_completed_at
                refreshed_backup.duration_seconds = original_duration_seconds
                refreshed_backup.save(update_fields=[
                    'status', 'file_path', 'file_size', 'checksum', 
                    'completed_at', 'duration_seconds'
                ])
                
                if is_upload:
                    self.log_info(f"ğŸ›¡ï¸ Sauvegarde source protÃ©gÃ©e avec succÃ¨s pour upload")
                else:
                    self.log_info(f"âœ… MÃ©tadonnÃ©es de la sauvegarde source restaurÃ©es complÃ¨tement")
        except Exception as e:
            self.log_warning(f"âš ï¸ Impossible de vÃ©rifier/restaurer l'Ã©tat de la sauvegarde source: {e}")
        
        return stats
    
    def _handle_database_replacement(self, restore_history: RestoreHistory, restore_options: Dict[str, Any]) -> RestoreHistory:
        """GÃ¨re le cas oÃ¹ la base de donnÃ©es a Ã©tÃ© complÃ¨tement remplacÃ©e"""
        self.log_warning("ğŸ”„ Base de donnÃ©es remplacÃ©e - Gestion spÃ©ciale du RestoreHistory")
        
        # Sauvegarder les donnÃ©es de l'ancien historique
        old_restore_history = restore_history
        original_backup = restore_history.backup_source
        
        # CrÃ©er un nouveau BackupHistory dans la nouvelle base sans modifier l'original
        new_backup = self._create_compatible_backup_history(original_backup, restore_history.created_by)
        
        # CrÃ©er un nouveau RestoreHistory avec le nouveau BackupHistory
        new_restore_history = self._create_compatible_restore_history(
            old_restore_history, new_backup, restore_options
        )
        
        # Nettoyer l'ancien restore_history sans toucher Ã  la sauvegarde d'origine
        try:
            # Au lieu de supprimer l'historique, on le marque comme terminÃ©
            old_restore_history.status = 'completed'
            old_restore_history.completed_at = timezone.now()
            old_restore_history.save(update_fields=['status', 'completed_at'])
            self.log_info(f"âœ… Ancien RestoreHistory marquÃ© comme terminÃ©: ID {old_restore_history.id}")
        except Exception as e:
            self.log_warning(f"âš ï¸ Impossible de mettre Ã  jour l'ancien RestoreHistory: {e}")
        
        return new_restore_history
    
    def _create_compatible_backup_history(self, original_backup: BackupHistory, user) -> BackupHistory:
        """CrÃ©e un BackupHistory compatible avec la nouvelle base sans modifier l'original"""
        # CrÃ©er une copie de la sauvegarde d'origine avec un nom diffÃ©rent
        new_backup = BackupHistory.objects.create(
            backup_name=f"Copie_{original_backup.backup_name}_{timezone.now().strftime('%Y%m%d_%H%M%S')}",
            status='completed',  # Toujours marquer comme terminÃ©e
            backup_type=original_backup.backup_type,
            file_path=original_backup.file_path,
            file_size=original_backup.file_size,
            checksum=original_backup.checksum,
            started_at=timezone.now(),
            completed_at=timezone.now(),
            duration_seconds=0,
            created_by=user
        )
        
        self.log_info(f"ğŸ”„ Nouveau BackupHistory crÃ©Ã©: ID {new_backup.id} (copie de ID {original_backup.id})")
        return new_backup
    
    def _create_compatible_restore_history(self, old_restore_history: RestoreHistory, new_backup: BackupHistory, restore_options: Dict[str, Any]) -> RestoreHistory:
        """CrÃ©e un RestoreHistory compatible avec la nouvelle base"""
        new_restore_history = RestoreHistory.objects.create(
            backup_source=new_backup,
            restore_name=f"{old_restore_history.restore_name}_db_replaced",
            restore_type=old_restore_history.restore_type,
            status='running',
            restore_options=restore_options,
            started_at=old_restore_history.started_at,
            created_by=old_restore_history.created_by
        )
        
        self.log_info(f"ğŸ”„ Nouveau RestoreHistory crÃ©Ã©: ID {new_restore_history.id}")
        return new_restore_history
    
    def _finalize_restore(self, restore_history: RestoreHistory, stats: Dict[str, Any]) -> None:
        """Finalise la restauration en mettant Ã  jour l'historique"""
        duration = self.end_operation(f"Restauration {restore_history.restore_name}")
        
        restore_history.status = 'completed'
        restore_history.completed_at = timezone.now()
        restore_history.duration_seconds = duration
        restore_history.tables_restored = stats['tables_restored']
        restore_history.records_restored = stats['records_restored']
        restore_history.files_restored = stats['files_restored']
        restore_history.log_data = self.get_logs_summary()
        
        # Sauvegarder explicitement tous les champs
        try:
            restore_history.save()
            self.log_info(f"âœ… Restauration ID {restore_history.id} terminÃ©e avec succÃ¨s - statut mis Ã  jour: completed")
        except Exception as e:
            self.log_error(f"â— Erreur lors de la mise Ã  jour du statut de restauration: {str(e)}", e)
            # Tentative de sauvegarde avec moins de champs
            try:
                restore_history.save(update_fields=['status', 'completed_at', 'duration_seconds'])
                self.log_info(f"âœ… Restauration ID {restore_history.id} terminÃ©e - mise Ã  jour partielle rÃ©ussie")
            except Exception as e2:
                self.log_error(f"âŒ Ã‰chec critique de mise Ã  jour du statut: {str(e2)}", e2)
        
        self.log_info(f"âœ… Restauration terminÃ©e en {duration}s")
    
    def _handle_restore_failure(self, restore_history: RestoreHistory, error: Exception) -> None:
        """GÃ¨re l'Ã©chec de la restauration"""
        restore_history.status = 'failed'
        restore_history.completed_at = timezone.now()
        restore_history.error_message = str(error)
        restore_history.log_data = self.get_logs_summary()
        
        try:
            restore_history.save()
            self.log_info(f"âŒ Restauration ID {restore_history.id} marquÃ©e comme Ã©chouÃ©e")
        except Exception as e:
            self.log_error(f"â— Erreur lors de la mise Ã  jour du statut d'Ã©chec: {str(e)}", e)
            # Tentative de sauvegarde avec moins de champs
            try:
                restore_history.save(update_fields=['status', 'completed_at', 'error_message'])
                self.log_info(f"âŒ Restauration ID {restore_history.id} marquÃ©e comme Ã©chouÃ©e (mise Ã  jour partielle)")
            except Exception as e2:
                self.log_error(f"âŒ Ã‰chec critique de mise Ã  jour du statut d'Ã©chec: {str(e2)}", e2)
        
        self.log_error("âŒ Ã‰chec de la restauration", error)
    
    def _cleanup_after_restore(self, work_dir: Path) -> None:
        """Effectue le nettoyage aprÃ¨s la restauration"""
        self._cleanup_restore_directory(work_dir)
        self._auto_cleanup_temp_files()
    
    def _create_restore_directory(self, restore_name: str) -> Path:
        """CrÃ©e le rÃ©pertoire de travail pour la restauration"""
        restore_dir = self.ensure_backup_directory() / "restore_temp" / restore_name
        restore_dir.mkdir(parents=True, exist_ok=True)
        return restore_dir
    
    def _restore_metadata(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les mÃ©tadonnÃ©es Django"""
        self.log_info("ğŸ“‹ Phase 1: Restauration des mÃ©tadonnÃ©es")
        
        metadata_file = extract_dir / self.METADATA_FILENAME
        if not metadata_file.exists():
            self.log_warning("âš ï¸ Fichier de mÃ©tadonnÃ©es introuvable")
            return {'records_restored': 0, 'tables_restored': 0, 'metadata_restored': 0}
        
        # Options de restauration des mÃ©tadonnÃ©es
        metadata_options = {
            'flush_before': restore_options.get('flush_metadata', False),
            'ignore_duplicates': restore_options.get('ignore_duplicates', True)
        }
        
        try:
            stats = self.metadata_service.import_metadata(metadata_file, metadata_options)
            
            if stats.get('success', True):
                self.log_info(f"âœ… MÃ©tadonnÃ©es restaurÃ©es: {stats['records_imported']} enregistrements")
                return {
                    'records_restored': stats['records_imported'],
                    'tables_restored': stats['models_imported'],
                    'metadata_restored': stats['records_imported']
                }
            else:
                error_msg = stats.get('error', 'Erreur inconnue')
                self.log_warning(f"âš ï¸ Import des mÃ©tadonnÃ©es Ã©chouÃ©: {error_msg}")
                
                return {
                    'records_restored': 0,
                    'tables_restored': 0, 
                    'metadata_restored': 0,
                    'metadata_error': error_msg
                }
        
        except Exception as e:
            self.log_warning(f"âš ï¸ Erreur lors de la restauration des mÃ©tadonnÃ©es: {str(e)}")
            self.log_info("ğŸ“ Poursuite de la restauration sans les mÃ©tadonnÃ©es")
            
            return {
                'records_restored': 0,
                'tables_restored': 0,
                'metadata_restored': 0,
                'metadata_error': str(e)
            }
    
    def _restore_database_data(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les donnÃ©es de la base de donnÃ©es"""
        self.log_info("ğŸ—„ï¸ Phase 2: Restauration des donnÃ©es SQL")
        
        db_settings = settings.DATABASES['default']
        engine = db_settings['ENGINE']
        
        try:
            if 'sqlite3' in engine:
                return self._restore_sqlite(extract_dir, db_settings, restore_options)
            elif 'postgresql' in engine:
                return self._restore_postgresql(extract_dir, db_settings, restore_options)
            elif 'mysql' in engine:
                return self._restore_mysql(extract_dir, db_settings, restore_options)
            else:
                self.log_warning(f"âš ï¸ Moteur de DB non supportÃ© pour restauration: {engine}")
                return {'data_restored': 0}
                
        except Exception as e:
            raise DatabaseRestoreError(f"Erreur lors de la restauration de la base {engine}: {e}")
    
    def _restore_sqlite(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration spÃ©cifique pour SQLite avec gestion sÃ©curisÃ©e des contraintes"""
        # VÃ©rifier la disponibilitÃ© du fichier SQL de donnÃ©es
        backup_sql_file = extract_dir / self.DATABASE_DUMP_FILENAME
        backup_db_file = extract_dir / self.DATABASE_SQLITE_FILENAME
        
        # Prioriser le fichier SQL s'il existe (plus sÃ»r pour la restauration)
        if backup_sql_file.exists():
            return self._restore_sqlite_from_sql(backup_sql_file, db_settings, restore_options)
        elif backup_db_file.exists():
            return self._restore_sqlite_from_db(backup_db_file, db_settings, restore_options)
        else:
            self.log_warning("âš ï¸ Aucun fichier SQLite de sauvegarde trouvÃ©")
            return {'data_restored': 0}
    
    def _restore_sqlite_from_sql(self, sql_file: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration SQLite sÃ©curisÃ©e depuis un fichier SQL avec gestion avancÃ©e des contraintes FK"""
        current_db_path = Path(db_settings['NAME'])
        
        try:
            # Connexion Ã  la base de donnÃ©es actuelle
            conn = sqlite3.connect(str(current_db_path))
            cursor = conn.cursor()
            
            # Diagnostic et prÃ©paration
            fk_enabled = self._prepare_sqlite_restore(cursor)
            
            # ExÃ©cuter la restauration dans une transaction
            stats = self._execute_sqlite_restore_transaction(cursor, sql_file, restore_options, fk_enabled)
            
            conn.close()
            
            self._log_sqlite_restore_summary(stats)
            
            return {
                'data_restored': stats['executed_statements'],
                'total_statements': stats['total_statements'],
                'failed_statements': stats['failed_statements'],
                'fk_violations': stats['fk_violations'],
                'success_rate': stats['success_rate']
            }
            
        except Exception as e:
            # En cas d'erreur, nettoyer et relancer
            self._cleanup_sqlite_connection(cursor, conn, fk_enabled)
            raise DatabaseRestoreError(f"Erreur lors de la restauration SQLite: {str(e)}")
    
    def _prepare_sqlite_restore(self, cursor) -> bool:
        """PrÃ©pare la base SQLite pour la restauration"""
        self.log_info("ğŸ” Analyse du fichier SQL et prÃ©paration...")
        
        # VÃ©rifier l'intÃ©gritÃ© avant restauration
        cursor.execute("PRAGMA integrity_check")
        initial_integrity = cursor.fetchone()[0]
        self.log_info(f"ğŸ“‹ IntÃ©gritÃ© initiale: {initial_integrity}")
        
        # Sauvegarder l'Ã©tat des contraintes FK
        cursor.execute("PRAGMA foreign_keys")
        fk_enabled = cursor.fetchone()[0]
        self.log_info(f"ğŸ”— Contraintes FK initialement: {'activÃ©es' if fk_enabled else 'dÃ©sactivÃ©es'}")
        
        # DÃ©sactiver temporairement les contraintes FK
        cursor.execute("PRAGMA foreign_keys = OFF")
        cursor.execute("PRAGMA defer_foreign_keys = ON")
        self.log_info("ğŸ”“ Contraintes FK temporairement dÃ©sactivÃ©es")
        
        return bool(fk_enabled)
    
    def _execute_sqlite_restore_transaction(self, cursor, sql_file: Path, restore_options: Dict[str, Any], fk_enabled: bool) -> Dict[str, Any]:
        """ExÃ©cute la restauration SQLite dans une transaction"""
        # Commencer une transaction dÃ©fÃ©rÃ©e
        cursor.execute("BEGIN DEFERRED TRANSACTION")
        
        # Optionnellement vider les tables si demandÃ©
        if restore_options.get('flush_before', False):
            self._flush_sqlite_tables(cursor)
        
        # PrÃ©processer et exÃ©cuter le script SQL
        stats = self._execute_sql_statements(cursor, sql_file, restore_options)
        
        # VÃ©rifier les contraintes avant commit
        fk_violations = self._check_sqlite_constraints(cursor, restore_options)
        stats['fk_violations'] = len(fk_violations)
        
        # Valider la transaction
        cursor.execute("COMMIT")
        self.log_info("âœ… Transaction validÃ©e avec succÃ¨s")
        
        # Restaurer l'Ã©tat des contraintes
        cursor.execute(f"PRAGMA foreign_keys = {'ON' if fk_enabled else 'OFF'}")
        cursor.execute("PRAGMA defer_foreign_keys = OFF")
        
        # VÃ©rification finale d'intÃ©gritÃ©
        self._verify_sqlite_integrity(cursor)
        
        return stats
    
    def _flush_sqlite_tables(self, cursor) -> None:
        """Vide les tables SQLite existantes"""
        self.log_info("ğŸ—‘ï¸ Suppression des donnÃ©es existantes...")
        
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' 
            AND name NOT LIKE 'sqlite_%' 
            AND name NOT IN ('django_migrations', 'auth_permission', 'django_content_type')
            ORDER BY name
        """)
        tables = cursor.fetchall()
        
        for table in tables:
            table_name = table[0]
            try:
                cursor.execute(f"DELETE FROM {table_name}")
                self.log_debug(f"  âœ… Table {table_name} vidÃ©e")
            except sqlite3.Error as e:
                self.log_warning(f"  âš ï¸ Impossible de vider {table_name}: {e}")
    
    def _execute_sql_statements(self, cursor, sql_file: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """ExÃ©cute les statements SQL avec gestion intelligente des erreurs"""
        self.log_info("ğŸ“¥ Import des donnÃ©es SQL avec gestion intelligente des erreurs...")
        
        with open(sql_file, 'r', encoding='utf-8') as f:
            sql_content = f.read()
        
        statements = self._parse_sql_statements(sql_content)
        
        # Filtrer les statements pour les uploads (exclure les tables systÃ¨me)
        if restore_options.get('upload_source', False):
            original_count = len(statements)
            statements = self._filter_system_tables(statements)
            self.log_info(f"ğŸ›¡ï¸ UPLOAD DÃ‰TECTÃ‰ - EXCLUSION DES TABLES SYSTÃˆME")
            self.log_info(f"ğŸ›¡ï¸ Statements filtrÃ©s: {original_count} -> {len(statements)}")
            print(f"ğŸ›¡ï¸ UPLOAD DÃ‰TECTÃ‰ - EXCLUSION DES TABLES SYSTÃˆME")  # Log visible dans la console
            print(f"ğŸ›¡ï¸ Statements filtrÃ©s: {original_count} -> {len(statements)}")
        else:
            print(f"âšª PAS D'UPLOAD DÃ‰TECTÃ‰ - upload_source={restore_options.get('upload_source')}")
        
        executed_statements = 0
        failed_statements = []
        deferred_statements = []
        
        # Premier passage: exÃ©cuter les statements non problÃ©matiques
        for i, statement in enumerate(statements):
            statement = statement.strip()
            if not statement or statement.startswith('--'):
                continue
            
            try:
                cursor.execute(statement)
                executed_statements += 1
            except sqlite3.Error as e:
                if self._handle_sql_error(cursor, e, statement, i, restore_options, deferred_statements, failed_statements):
                    executed_statements += 1
        
        # DeuxiÃ¨me passage: retry des statements diffÃ©rÃ©s
        executed_statements += self._retry_deferred_statements(cursor, deferred_statements, failed_statements)
        
        success_rate = executed_statements / len(statements) * 100 if statements else 0
        
        return {
            'executed_statements': executed_statements,
            'total_statements': len(statements),
            'failed_statements': len(failed_statements),
            'success_rate': success_rate
        }
    
    def _handle_sql_error(self, cursor, error: sqlite3.Error, statement: str, line_num: int, restore_options: Dict[str, Any], 
                         deferred_statements: List[Tuple[str, int]], failed_statements: List[Tuple[str, str, int]]) -> bool:
        """GÃ¨re les erreurs SQL de maniÃ¨re intelligente"""
        error_msg = str(error)
        
        if "UNIQUE constraint failed" in error_msg:
            if restore_options.get('ignore_duplicates', True):
                self.log_debug(f"âš ï¸ Doublon ignorÃ©: {error_msg}")
                return False
        elif "FOREIGN KEY constraint failed" in error_msg:
            deferred_statements.append((statement, line_num))
            self.log_debug(f"ğŸ”„ Statement diffÃ©rÃ© pour FK: ligne {line_num}")
            return False
        elif "NOT NULL constraint failed" in error_msg:
            corrected_statement = self._fix_not_null_statement(statement, error_msg)
            if corrected_statement != statement:
                try:
                    cursor.execute(corrected_statement)
                    self.log_info("ğŸ”§ Statement corrigÃ© pour NOT NULL")
                    return True
                except sqlite3.Error:
                    pass
            deferred_statements.append((statement, line_num))
            return False
        
        # Autres erreurs: logger et continuer
        failed_statements.append((statement, error_msg, line_num))
        self.log_warning(f"âš ï¸ Erreur SQL ligne {line_num}: {error_msg}")
        return False
    
    def _retry_deferred_statements(self, cursor, deferred_statements: List[Tuple[str, int]], 
                                 failed_statements: List[Tuple[str, str, int]]) -> int:
        """Retry des statements diffÃ©rÃ©s avec logique d'attente"""
        if not deferred_statements:
            return 0
        
        self.log_info(f"ğŸ”„ Retry de {len(deferred_statements)} statements diffÃ©rÃ©s...")
        
        executed_count = 0
        retry_count = 0
        
        while deferred_statements and retry_count < self.MAX_SQL_RETRIES:
            retry_count += 1
            remaining_statements = []
            
            for statement, line_num in deferred_statements:
                try:
                    cursor.execute(statement)
                    executed_count += 1
                    self.log_debug(f"âœ… Statement retry rÃ©ussi: ligne {line_num}")
                except sqlite3.Error as e:
                    remaining_statements.append((statement, line_num))
                    if retry_count == self.MAX_SQL_RETRIES:
                        failed_statements.append((statement, str(e), line_num))
            
            deferred_statements = remaining_statements
            
            if remaining_statements:
                self.log_info(f"ğŸ”„ Retry {retry_count}/{self.MAX_SQL_RETRIES}: {len(remaining_statements)} statements restants")
        
        return executed_count
    
    def _check_sqlite_constraints(self, cursor, restore_options: Dict[str, Any]) -> List[Tuple]:
        """VÃ©rifie les contraintes SQLite avant commit"""
        self.log_info("ğŸ” VÃ©rification des contraintes avant commit...")
        
        # RÃ©activer temporairement les FK pour vÃ©rifier
        cursor.execute("PRAGMA foreign_keys = ON")
        cursor.execute("PRAGMA foreign_key_check")
        fk_violations = cursor.fetchall()
        
        if fk_violations:
            self.log_warning(f"âš ï¸ {len(fk_violations)} violations de FK dÃ©tectÃ©es:")
            for violation in fk_violations[:5]:  # Afficher seulement les 5 premiÃ¨res
                self.log_warning(f"  - Table: {violation[0]}, FK: {violation[3]}")
            
            if not restore_options.get('ignore_fk_violations', True):
                raise DatabaseRestoreError(f"Violations de contraintes FK dÃ©tectÃ©es: {len(fk_violations)}")
            else:
                self.log_info("ğŸ”§ Violations FK ignorÃ©es selon les options")
        
        return fk_violations
    
    def _verify_sqlite_integrity(self, cursor) -> None:
        """VÃ©rifie l'intÃ©gritÃ© finale de la base SQLite"""
        cursor.execute("PRAGMA integrity_check")
        final_integrity = cursor.fetchone()[0]
        
        if final_integrity == "ok":
            self.log_info("âœ… VÃ©rification d'intÃ©gritÃ© finale rÃ©ussie")
        else:
            self.log_warning(f"âš ï¸ ProblÃ¨me d'intÃ©gritÃ© finale: {final_integrity}")
    
    def _log_sqlite_restore_summary(self, stats: Dict[str, Any]) -> None:
        """Log le rÃ©sumÃ© de la restauration SQLite"""
        self.log_info("âœ… Base SQLite restaurÃ©e:")
        self.log_info(f"  ğŸ“Š {stats['executed_statements']}/{stats['total_statements']} statements exÃ©cutÃ©es ({stats['success_rate']:.1f}%)")
        self.log_info(f"  âŒ {stats['failed_statements']} statements Ã©chouÃ©es")
        self.log_info(f"  ğŸ”— {stats['fk_violations']} violations FK dÃ©tectÃ©es")
    
    def _cleanup_sqlite_connection(self, cursor, conn, fk_enabled: bool) -> None:
        """Nettoie la connexion SQLite en cas d'erreur"""
        try:
            cursor.execute("ROLLBACK")
            cursor.execute(f"PRAGMA foreign_keys = {'ON' if fk_enabled else 'OFF'}")
            cursor.execute("PRAGMA defer_foreign_keys = OFF")
            conn.close()
        except Exception:
            pass
    
    def _parse_sql_statements(self, sql_content: str) -> List[str]:
        """Parse les statements SQL de maniÃ¨re intelligente en gÃ©rant les statements multi-lignes"""
        # Supprimer les commentaires
        sql_content = re.sub(r'--.*$', '', sql_content, flags=re.MULTILINE)
        
        # SÃ©parer par ';' mais en tenant compte des strings
        statements = []
        current_statement = ""
        in_string = False
        string_char = None
        
        i = 0
        while i < len(sql_content):
            char = sql_content[i]
            
            if not in_string:
                if char in ['"', "'"]:
                    in_string = True
                    string_char = char
                elif char == ';':
                    statements.append(current_statement.strip())
                    current_statement = ""
                    i += 1
                    continue
            else:
                if char == string_char and (i == 0 or sql_content[i-1] != '\\'):
                    in_string = False
                    string_char = None
            
            current_statement += char
            i += 1
        
        # Ajouter le dernier statement s'il existe
        if current_statement.strip():
            statements.append(current_statement.strip())
        
        return statements
    
    def _filter_system_tables(self, statements: List[str]) -> List[str]:
        """Filtre les statements pour exclure les tables systÃ¨me lors d'un upload"""
        # Tables systÃ¨me Ã  exclure lors d'un upload
        system_tables = [
            'backup_manager_backuphistory',
            'backup_manager_restorehistory',
            'backup_manager_backupconfiguration'
        ]
        
        filtered_statements = []
        excluded_count = 0
        
        for statement in statements:
            statement_upper = statement.upper()
            should_exclude = False
            
            # VÃ©rifier si le statement concerne une table systÃ¨me
            for table in system_tables:
                if any(pattern in statement_upper for pattern in [
                    f'INSERT INTO "{table.upper()}"',
                    f'INSERT INTO {table.upper()}',
                    f'UPDATE "{table.upper()}"',
                    f'UPDATE {table.upper()}',
                    f'DELETE FROM "{table.upper()}"',
                    f'DELETE FROM {table.upper()}',
                    f'DROP TABLE "{table.upper()}"',
                    f'DROP TABLE {table.upper()}',
                    f'CREATE TABLE "{table.upper()}"',
                    f'CREATE TABLE {table.upper()}'
                ]):
                    should_exclude = True
                    break
            
            if should_exclude:
                excluded_count += 1
                self.log_debug(f"ğŸš« Statement exclu (table systÃ¨me): {statement[:50]}...")
            else:
                filtered_statements.append(statement)
        
        if excluded_count > 0:
            self.log_info(f"ğŸ›¡ï¸ {excluded_count} statements de tables systÃ¨me exclus pour prÃ©server l'historique")
        
        return filtered_statements
    
    def _fix_not_null_statement(self, statement: str, error_msg: str) -> str:
        """Tente de corriger un statement qui viole une contrainte NOT NULL"""
        # Extraire le nom de la colonne de l'erreur
        match = re.search(r'NOT NULL constraint failed: (\w+)\.(\w+)', error_msg)
        if not match:
            return statement
        
        table_name, column_name = match.groups()
        
        # Si c'est un INSERT, tenter d'ajouter une valeur par dÃ©faut
        if statement.upper().startswith('INSERT') and column_name in self.DEFAULT_NOT_NULL_VALUES:
            self.log_info(f"ğŸ”§ Tentative de correction NOT NULL pour {table_name}.{column_name}")
            # Cette logique pourrait Ãªtre amÃ©liorÃ©e selon les besoins
        
        return statement
    
    def _restore_sqlite_from_db(self, backup_db_file: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration SQLite depuis un fichier de base de donnÃ©es (mÃ©thode de remplacement - moins sÃ»re)"""
        current_db_path = Path(db_settings['NAME'])
        
        # Sauvegarde de la DB actuelle si demandÃ© - DÃ‰SACTIVÃ‰ TEMPORAIREMENT
        # if restore_options.get('backup_current', True):
        #     self._backup_current_database(current_db_path)
        
        # Avertissement sur cette mÃ©thode
        self.log_warning("âš ï¸ Utilisation de la mÃ©thode de remplacement de DB (moins sÃ»re)")
        
        # Remplacement de la base de donnÃ©es
        if current_db_path.exists():
            current_db_path.unlink()
        
        shutil.copy2(backup_db_file, current_db_path)
        
        file_size = current_db_path.stat().st_size
        self.log_info(f"âœ… Base SQLite restaurÃ©e par remplacement: {self.format_size(file_size)}")
        
        # IMPORTANT: Marquer que la DB a Ã©tÃ© complÃ¨tement remplacÃ©e
        return {
            'data_restored': 1, 
            'database_replaced': True  # Nouvelle clÃ© pour indiquer le remplacement complet
        }
    
    def _backup_current_database(self, current_db_path: Path) -> None:
        """Sauvegarde la base de donnÃ©es actuelle"""
        backup_current_path = current_db_path.with_suffix(f'.backup_{timezone.now().strftime("%Y%m%d_%H%M%S")}.sqlite3')
        if current_db_path.exists():
            shutil.copy2(current_db_path, backup_current_path)
            self.log_info(f"ğŸ’¾ DB actuelle sauvegardÃ©e: {backup_current_path}")
    
    def _restore_postgresql(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration spÃ©cifique pour PostgreSQL"""
        dump_file = extract_dir / self.DATABASE_DUMP_FILENAME
        if not dump_file.exists():
            self.log_warning("âš ï¸ Dump PostgreSQL introuvable")
            return {'data_restored': 0}
        
        # Drop et recrÃ©ation de la DB si demandÃ©
        # Note: La sauvegarde automatique est dÃ©sactivÃ©e temporairement
        if restore_options.get('drop_before_restore', False):
            # Pas de sauvegarde automatique avant le drop
            self._drop_postgresql_database(db_settings)
            self._create_postgresql_database(db_settings)
        
        # Restauration avec psql
        cmd = [
            'psql',
            f"--host={db_settings.get('HOST', 'localhost')}",
            f"--port={db_settings.get('PORT', 5432)}",
            f"--username={db_settings['USER']}",
            f"--dbname={db_settings['NAME']}",
            '--quiet',
            f"--file={dump_file}"
        ]
        
        env = {'PGPASSWORD': db_settings.get('PASSWORD', '')} if db_settings.get('PASSWORD') else {}
        
        try:
            result = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=3600)
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, cmd, result.stderr)
            
            self.log_info("âœ… Base PostgreSQL restaurÃ©e")
            return {'data_restored': 1}
            
        except subprocess.CalledProcessError as e:
            raise DatabaseRestoreError(f"Erreur psql: {e.stderr}")
        except subprocess.TimeoutExpired:
            raise DatabaseRestoreError("Timeout lors de la restauration PostgreSQL")
    
    def _restore_mysql(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration spÃ©cifique pour MySQL"""
        # ParamÃ¨tre restore_options disponible pour futures options
        # Note: La sauvegarde automatique est dÃ©sactivÃ©e temporairement
        _ = restore_options  # Marquer comme intentionnellement inutilisÃ©
        
        dump_file = extract_dir / self.DATABASE_DUMP_FILENAME
        if not dump_file.exists():
            self.log_warning("âš ï¸ Dump MySQL introuvable")
            return {'data_restored': 0}
        
        # Pas de sauvegarde automatique avant la restauration
        
        cmd = [
            'mysql',
            f"--host={db_settings.get('HOST', 'localhost')}",
            f"--port={db_settings.get('PORT', 3306)}",
            f"--user={db_settings['USER']}",
            f"--password={db_settings.get('PASSWORD', '')}",
            db_settings['NAME']
        ]
        
        try:
            with open(dump_file, 'r') as f:
                result = subprocess.run(cmd, stdin=f, capture_output=True, text=True, timeout=3600)
            
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, cmd, result.stderr)
            
            self.log_info("âœ… Base MySQL restaurÃ©e")
            return {'data_restored': 1}
            
        except subprocess.CalledProcessError as e:
            raise DatabaseRestoreError(f"Erreur mysql: {e.stderr}")
        except subprocess.TimeoutExpired:
            raise DatabaseRestoreError("Timeout lors de la restauration MySQL")
    
    def _restore_files(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les fichiers systÃ¨me"""
        self.log_info("ğŸ“ Phase 3: Restauration des fichiers")
        
        files_dir = extract_dir / self.FILES_DIRNAME
        if not files_dir.exists():
            self.log_warning("âš ï¸ RÃ©pertoire de fichiers introuvable")
            return {'files_restored': 0}
        
        try:
            files_restored = 0
            
            # PROTECTION: Ne pas restaurer les fichiers media lors d'un upload
            # pour Ã©viter de supprimer les sauvegardes existantes
            if not restore_options.get('upload_source', False):
                # Restauration des fichiers media seulement pour les restaurations normales
                files_restored += self._restore_media_files(files_dir, restore_options)
            else:
                self.log_info("ğŸ›¡ï¸ Upload dÃ©tectÃ© - restauration des fichiers media ignorÃ©e pour prÃ©server les sauvegardes")
            
            # Restauration des logs (toujours autorisÃ©e)
            files_restored += self._restore_log_files(files_dir, restore_options)
            
            self.log_info(f"âœ… {files_restored} fichiers restaurÃ©s")
            return {'files_restored': files_restored}
            
        except Exception as e:
            raise FileRestoreError(f"Erreur lors de la restauration des fichiers: {e}")
    
    def _restore_media_files(self, files_dir: Path, restore_options: Dict[str, Any]) -> int:
        """Restaure les fichiers media"""
        media_source = files_dir / "media"
        if not (media_source.exists() and hasattr(settings, 'MEDIA_ROOT')):
            return 0
        
        media_dest = Path(settings.MEDIA_ROOT)
        
        # Sauvegarde des fichiers media actuels - DÃ‰SACTIVÃ‰ TEMPORAIREMENT
        # if restore_options.get('backup_current_files', True):
        #     self._backup_current_media_files(media_dest)
        
        # Restauration
        if media_dest.exists():
            shutil.rmtree(media_dest)
        shutil.copytree(media_source, media_dest, dirs_exist_ok=True)
        
        files_count = sum(1 for _ in media_dest.rglob('*') if _.is_file())
        self.log_info(f"ğŸ“· Fichiers media restaurÃ©s: {media_dest}")
        
        return files_count
    
    def _backup_current_media_files(self, media_dest: Path) -> None:
        """Sauvegarde les fichiers media actuels"""
        backup_media_path = media_dest.parent / f"media_backup_{timezone.now().strftime('%Y%m%d_%H%M%S')}"
        if media_dest.exists():
            shutil.copytree(media_dest, backup_media_path, dirs_exist_ok=True)
            self.log_info(f"ğŸ’¾ Fichiers media actuels sauvegardÃ©s: {backup_media_path}")
    
    def _restore_log_files(self, files_dir: Path, restore_options: Dict[str, Any]) -> int:
        """Restaure les fichiers de logs"""
        logs_source = files_dir / "logs"
        if not logs_source.exists():
            return 0
        
        logs_dest = Path('logs')
        
        if restore_options.get('merge_logs', True):
            # Fusion avec les logs existants
            if logs_dest.exists():
                shutil.copytree(logs_source, logs_dest, dirs_exist_ok=True)
            else:
                shutil.copytree(logs_source, logs_dest)
        else:
            # Remplacement complet
            if logs_dest.exists():
                shutil.rmtree(logs_dest)
            shutil.copytree(logs_source, logs_dest)
        
        files_count = sum(1 for _ in logs_dest.rglob('*') if _.is_file())
        self.log_info(f"ğŸ“‹ Logs restaurÃ©s: {logs_dest}")
        
        return files_count
    
    def _cleanup_restore_directory(self, restore_dir: Path) -> None:
        """Nettoie le rÃ©pertoire temporaire de restauration"""
        try:
            if restore_dir.exists():
                shutil.rmtree(restore_dir)
                self.log_info(f"ğŸ§¹ RÃ©pertoire temporaire nettoyÃ©: {restore_dir}")
        except Exception as e:
            self.log_warning(f"âš ï¸ Impossible de nettoyer {restore_dir}: {e}")
    
    def _drop_postgresql_database(self, db_settings: Dict[str, Any]) -> None:
        """Supprime une base PostgreSQL"""
        # Cette fonction nÃ©cessite des privilÃ¨ges administrateur
        # Ã€ implÃ©menter selon les besoins spÃ©cifiques
        pass
    
    def _create_postgresql_database(self, db_settings: Dict[str, Any]) -> None:
        """CrÃ©e une base PostgreSQL"""
        # Cette fonction nÃ©cessite des privilÃ¨ges administrateur
        # Ã€ implÃ©menter selon les besoins spÃ©cifiques
        pass
    
    def _auto_cleanup_temp_files(self) -> None:
        """Nettoyage automatique des fichiers temporaires anciens"""
        try:
            from .cleanup_service import CleanupService
            
            cleanup_service = CleanupService()
            # Nettoyer les fichiers de plus de 2h automatiquement
            results = cleanup_service.cleanup_all_temporary_files(max_age_hours=self.AUTO_CLEANUP_MAX_AGE_HOURS)
            
            # Log seulement si quelque chose a Ã©tÃ© nettoyÃ©
            if results['totals']['files_deleted'] > 0:
                self.log_info(
                    f"ğŸ§¹ Nettoyage automatique: "
                    f"{results['totals']['files_deleted']} fichiers temporaires supprimÃ©s, "
                    f"{cleanup_service.format_size(results['totals']['size_freed'])} libÃ©rÃ©s"
                )
        except Exception as e:
            # Ne pas faire Ã©chouer la restauration si le nettoyage Ã©choue
            self.log_warning(f"âš ï¸ Nettoyage automatique Ã©chouÃ©: {e}") 