"""
Service de restauration pour les sauvegardes
"""

import zipfile
import tempfile
import subprocess
import shutil
import re
import sqlite3
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from django.conf import settings
from django.utils import timezone
from ..models import BackupHistory, RestoreHistory
from .base_service import BaseService
from .metadata_service import MetadataService
from .storage_service import StorageService
from .encryption_service import EncryptionService


class RestoreError(Exception):
    """Exception sp√©cifique pour les erreurs de restauration"""
    pass


class DatabaseRestoreError(RestoreError):
    """Exception sp√©cifique pour les erreurs de restauration de base de donn√©es"""
    pass


class FileRestoreError(RestoreError):
    """Exception sp√©cifique pour les erreurs de restauration de fichiers"""
    pass


class RestoreService(BaseService):
    """Service pour restaurer les sauvegardes"""
    
    # Constantes
    DATABASE_DUMP_FILENAME = "database.sql"
    DATABASE_SQLITE_FILENAME = "database.sqlite3"
    METADATA_FILENAME = "metadata.json"
    FILES_DIRNAME = "files"
    
    AUTO_CLEANUP_MAX_AGE_HOURS = 2
    MAX_SQL_RETRIES = 3
    
    # Valeurs par d√©faut pour corrections NOT NULL
    DEFAULT_NOT_NULL_VALUES = {
        'encryption_enabled': 'TRUE',
        'compression_enabled': 'TRUE', 
        'encryption_algorithm': "'AES256'",
        'compression_level': '6',
        'created_at': "datetime('now')",
        'updated_at': "datetime('now')",
    }
    
    def __init__(self):
        super().__init__('RestoreService')
        self.metadata_service = MetadataService()
        self.storage_service = StorageService()
        self.encryption_service = EncryptionService()
    
    def restore_backup(self, backup: BackupHistory, user, restore_options: Optional[Dict[str, Any]] = None) -> RestoreHistory:
        """
        Restaure une sauvegarde
        
        Args:
            backup: Sauvegarde √† restaurer
            user: Utilisateur qui lance la restauration
            restore_options: Options de restauration
            
        Returns:
            Instance RestoreHistory cr√©√©e
        """
        restore_options = restore_options or {}
        restore_history = self._create_restore_history(backup, user, restore_options)
        
        try:
            self._execute_restore_workflow(backup, user, restore_options, restore_history)
            return restore_history
            
        except Exception as e:
            self._handle_restore_failure(restore_history, e)
            raise
    
    def _create_restore_history(self, backup: BackupHistory, user, restore_options: Dict[str, Any]) -> RestoreHistory:
        """Cr√©e l'enregistrement d'historique de restauration"""
        restore_name = f"Restauration_{backup.backup_name}_{timezone.now().strftime('%Y%m%d_%H%M%S')}"
        restore_type = restore_options.get('restore_type', 'full')
        
        return RestoreHistory.objects.create(
            backup_source=backup,
            restore_name=restore_name,
            restore_type=restore_type,
            status='running',
            restore_options=restore_options,
            started_at=timezone.now(),
            created_by=user
        )
    
    def _execute_restore_workflow(self, backup: BackupHistory, user, restore_options: Dict[str, Any], restore_history: RestoreHistory) -> None:
        """Ex√©cute le workflow complet de restauration"""
        self.start_operation(f"Restauration {restore_history.restore_name}")
        
        # Pr√©paration des fichiers
        work_dir, extract_dir = self._prepare_restore_files(backup, user, restore_history.restore_name)
        
        try:
            # S'assurer que le statut est bien 'running'
            restore_history.status = 'running'
            restore_history.save(update_fields=['status'])
            self.log_info(f"üöÄ Statut de restauration mis √† jour: running (ID: {restore_history.id})")
            
            # Ex√©cution des phases de restauration
            stats = self._execute_restore_phases(extract_dir, restore_options, restore_history)
            
            # Finalisation
            self._finalize_restore(restore_history, stats)
            
            # Nettoyage
            self._cleanup_after_restore(work_dir)
            
        except Exception as e:
            self.log_error(f"‚ùå Erreur pendant la restauration: {str(e)}", e)
            self._handle_restore_failure(restore_history, e)
            self._cleanup_after_restore(work_dir)
            raise
    
    def _prepare_restore_files(self, backup: BackupHistory, user, restore_name: str) -> Tuple[Path, Path]:
        """Pr√©pare les fichiers n√©cessaires √† la restauration"""
        # R√©cup√©ration du fichier de sauvegarde
        backup_file = self.storage_service.get_backup_file(backup.file_path)
        if not backup_file:
            raise FileNotFoundError(f"Fichier de sauvegarde introuvable: {backup.file_path}")
        
        # V√©rifier que le fichier est bien un fichier et pas un r√©pertoire
        if not backup_file.is_file():
            raise FileRestoreError(f"Le chemin de sauvegarde n'est pas un fichier valide: {backup_file} (type: {type(backup_file).__name__})")
        
        # Cr√©ation du r√©pertoire de travail
        work_dir = self._create_restore_directory(restore_name)
        self.log_info(f"üìÅ R√©pertoire de restauration: {work_dir}")
        
        # D√©chiffrement automatique si n√©cessaire
        source_file = self._handle_decryption_if_needed(backup_file, work_dir, user)
        
        # V√©rifier √† nouveau que le fichier source est valide apr√®s d√©chiffrement √©ventuel
        if not source_file.is_file():
            raise FileRestoreError(f"Le fichier source n'est pas valide apr√®s d√©chiffrement: {source_file}")
        
        # Extraction de l'archive
        extract_dir = self._extract_backup_archive(source_file, work_dir)
        
        return work_dir, extract_dir
    
    def _handle_decryption_if_needed(self, backup_file: Path, work_dir: Path, user) -> Path:
        """G√®re le d√©chiffrement du fichier si n√©cessaire"""
        if backup_file.suffix != '.encrypted':
            return backup_file
        
        decrypted_file = work_dir / "backup_decrypted.zip"
        system_key = self.encryption_service.generate_system_key(user)
        self.encryption_service.decrypt_file_with_key(backup_file, decrypted_file, system_key)
        self.log_info("üîì Fichier d√©chiffr√© automatiquement avec la cl√© syst√®me")
        
        return decrypted_file
    
    def _extract_backup_archive(self, archive_path: Path, work_dir: Path) -> Path:
        """Extrait l'archive de sauvegarde"""
        self.log_info("üì¶ Extraction de l'archive")
        
        extract_dir = work_dir / "extracted"
        extract_dir.mkdir(exist_ok=True)
        
        try:
            with zipfile.ZipFile(archive_path, 'r') as archive:
                # V√©rifier le contenu de l'archive avant extraction
                file_list = archive.namelist()
                self.log_info(f"üìã Archive contient {len(file_list)} fichiers/dossiers")
                
                # Extraire de mani√®re s√©curis√©e en v√©rifiant les chemins
                for file_path in file_list:
                    # V√©rifier si le chemin est s√©curis√© (pas de chemin absolu ou de remont√©e de r√©pertoire)
                    if file_path.startswith('/') or '..' in file_path:
                        self.log_warning(f"‚ö†Ô∏è Chemin non s√©curis√© ignor√©: {file_path}")
                        continue
                    
                    # Extraire le fichier avec son chemin relatif
                    target_path = extract_dir / file_path
                    
                    # Cr√©er le r√©pertoire parent si n√©cessaire
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Si c'est un r√©pertoire, juste cr√©er le dossier
                    if file_path.endswith('/'):
                        target_path.mkdir(parents=True, exist_ok=True)
                        continue
                    
                    # Extraire le fichier
                    with archive.open(file_path) as source, open(target_path, 'wb') as target:
                        shutil.copyfileobj(source, target)
            
            self.log_info(f"‚úÖ Archive extraite: {extract_dir}")
            return extract_dir
            
        except zipfile.BadZipFile as e:
            raise FileRestoreError(f"Archive corrompue: {e}")
        except Exception as e:
            raise FileRestoreError(f"Erreur lors de l'extraction: {e}")
    
    def _execute_restore_phases(self, extract_dir: Path, restore_options: Dict[str, Any], restore_history: RestoreHistory) -> Dict[str, Any]:
        """Ex√©cute les diff√©rentes phases de restauration"""
        restore_type = restore_options.get('restore_type', 'full')
        stats = {
            'tables_restored': 0,
            'records_restored': 0,
            'files_restored': 0
        }
        
        # Sauvegarder l'√©tat original de la sauvegarde source pour v√©rification ult√©rieure
        backup_source = restore_history.backup_source
        original_status = backup_source.status
        original_file_path = backup_source.file_path
        original_file_size = backup_source.file_size
        original_checksum = backup_source.checksum
        original_completed_at = backup_source.completed_at
        original_duration_seconds = backup_source.duration_seconds
        self.log_info(f"üìä √âtat initial de la sauvegarde source (ID: {backup_source.id}): {original_status}")
        
        # Phase 1: Restauration des m√©tadonn√©es
        if restore_type in ['full', 'metadata'] and (extract_dir / self.METADATA_FILENAME).exists():
            metadata_stats = self._restore_metadata(extract_dir, restore_options)
            stats.update(metadata_stats)
        
        # Phase 2: Restauration des donn√©es SQL
        if restore_type in ['full', 'data']:
            data_stats = self._restore_database_data(extract_dir, restore_options)
            stats.update(data_stats)
            
            # Gestion sp√©ciale si la base a √©t√© remplac√©e
            if data_stats.get('database_replaced', False):
                restore_history = self._handle_database_replacement(restore_history, restore_options)
        
        # Phase 3: Restauration des fichiers
        if restore_type == 'full' and (extract_dir / self.FILES_DIRNAME).exists():
            files_stats = self._restore_files(extract_dir, restore_options)
            stats['files_restored'] = files_stats.get('files_restored', 0)
        
        # PROTECTION RENFORC√âE: V√©rifier et prot√©ger la sauvegarde source
        # Cette v√©rification est critique pour les uploads car le SQL peut contenir
        # l'ancienne version avec statut 'running' au lieu de 'completed'
        try:
            # Recharger la sauvegarde source depuis la base de donn√©es
            refreshed_backup = BackupHistory.objects.get(id=backup_source.id)
            metadata_changed = (
                refreshed_backup.status != original_status or
                refreshed_backup.file_path != original_file_path or
                refreshed_backup.file_size != original_file_size or
                refreshed_backup.checksum != original_checksum or
                refreshed_backup.completed_at != original_completed_at
            )
            
            # PROTECTION SP√âCIALE POUR LES UPLOADS
            is_upload = restore_options.get('upload_source', False)
            if is_upload and refreshed_backup.status == 'running' and original_status == 'completed':
                self.log_warning(f"üõ°Ô∏è UPLOAD D√âTECT√â - Protection sauvegarde source ID {backup_source.id}")
                self.log_warning(f"üõ°Ô∏è Statut restaur√© forc√©ment: 'running' -> 'completed'")
                print(f"üõ°Ô∏è PROTECTION UPLOAD - Sauvegarde source {backup_source.id} forc√©e √† 'completed'")
                metadata_changed = True
            
            if metadata_changed:
                if is_upload:
                    self.log_warning(f"üõ°Ô∏è UPLOAD - La sauvegarde source (ID: {backup_source.id}) prot√©g√©e contre la modification")
                else:
                    self.log_warning(f"‚ö†Ô∏è La sauvegarde source (ID: {backup_source.id}) a √©t√© modifi√©e pendant la restauration")
                
                # Restaurer TOUTES les m√©tadonn√©es originales
                refreshed_backup.status = original_status
                refreshed_backup.file_path = original_file_path
                refreshed_backup.file_size = original_file_size
                refreshed_backup.checksum = original_checksum
                refreshed_backup.completed_at = original_completed_at
                refreshed_backup.duration_seconds = original_duration_seconds
                refreshed_backup.save(update_fields=[
                    'status', 'file_path', 'file_size', 'checksum', 
                    'completed_at', 'duration_seconds'
                ])
                
                if is_upload:
                    self.log_info(f"üõ°Ô∏è Sauvegarde source prot√©g√©e avec succ√®s pour upload")
                else:
                    self.log_info(f"‚úÖ M√©tadonn√©es de la sauvegarde source restaur√©es compl√®tement")
        except Exception as e:
            self.log_warning(f"‚ö†Ô∏è Impossible de v√©rifier/restaurer l'√©tat de la sauvegarde source: {e}")
        
        return stats
    
    def _handle_database_replacement(self, restore_history: RestoreHistory, restore_options: Dict[str, Any]) -> RestoreHistory:
        """G√®re le cas o√π la base de donn√©es a √©t√© compl√®tement remplac√©e"""
        self.log_warning("üîÑ Base de donn√©es remplac√©e - Gestion sp√©ciale du RestoreHistory")
        
        # Sauvegarder les donn√©es de l'ancien historique
        old_restore_history = restore_history
        original_backup = restore_history.backup_source
        
        # Cr√©er un nouveau BackupHistory dans la nouvelle base sans modifier l'original
        new_backup = self._create_compatible_backup_history(original_backup, restore_history.created_by)
        
        # Cr√©er un nouveau RestoreHistory avec le nouveau BackupHistory
        new_restore_history = self._create_compatible_restore_history(
            old_restore_history, new_backup, restore_options
        )
        
        # Nettoyer l'ancien restore_history sans toucher √† la sauvegarde d'origine
        try:
            # Au lieu de supprimer l'historique, on le marque comme termin√©
            old_restore_history.status = 'completed'
            old_restore_history.completed_at = timezone.now()
            old_restore_history.save(update_fields=['status', 'completed_at'])
            self.log_info(f"‚úÖ Ancien RestoreHistory marqu√© comme termin√©: ID {old_restore_history.id}")
        except Exception as e:
            self.log_warning(f"‚ö†Ô∏è Impossible de mettre √† jour l'ancien RestoreHistory: {e}")
        
        return new_restore_history
    
    def _create_compatible_backup_history(self, original_backup: BackupHistory, user) -> BackupHistory:
        """Cr√©e un BackupHistory compatible avec la nouvelle base sans modifier l'original"""
        # Cr√©er une copie de la sauvegarde d'origine avec un nom diff√©rent
        new_backup = BackupHistory.objects.create(
            backup_name=f"Copie_{original_backup.backup_name}_{timezone.now().strftime('%Y%m%d_%H%M%S')}",
            status='completed',  # Toujours marquer comme termin√©e
            backup_type=original_backup.backup_type,
            file_path=original_backup.file_path,
            file_size=original_backup.file_size,
            checksum=original_backup.checksum,
            started_at=timezone.now(),
            completed_at=timezone.now(),
            duration_seconds=0,
            created_by=user
        )
        
        self.log_info(f"üîÑ Nouveau BackupHistory cr√©√©: ID {new_backup.id} (copie de ID {original_backup.id})")
        return new_backup
    
    def _create_compatible_restore_history(self, old_restore_history: RestoreHistory, new_backup: BackupHistory, restore_options: Dict[str, Any]) -> RestoreHistory:
        """Cr√©e un RestoreHistory compatible avec la nouvelle base"""
        new_restore_history = RestoreHistory.objects.create(
            backup_source=new_backup,
            restore_name=f"{old_restore_history.restore_name}_db_replaced",
            restore_type=old_restore_history.restore_type,
            status='running',
            restore_options=restore_options,
            started_at=old_restore_history.started_at,
            created_by=old_restore_history.created_by
        )
        
        self.log_info(f"üîÑ Nouveau RestoreHistory cr√©√©: ID {new_restore_history.id}")
        return new_restore_history
    
    def _finalize_restore(self, restore_history: RestoreHistory, stats: Dict[str, Any]) -> None:
        """Finalise la restauration en mettant √† jour l'historique"""
        duration = self.end_operation(f"Restauration {restore_history.restore_name}")
        
        restore_history.status = 'completed'
        restore_history.completed_at = timezone.now()
        restore_history.duration_seconds = duration
        restore_history.tables_restored = stats['tables_restored']
        restore_history.records_restored = stats['records_restored']
        restore_history.files_restored = stats['files_restored']
        restore_history.log_data = self.get_logs_summary()
        
        # Sauvegarder explicitement tous les champs
        try:
            restore_history.save()
            self.log_info(f"‚úÖ Restauration ID {restore_history.id} termin√©e avec succ√®s - statut mis √† jour: completed")
        except Exception as e:
            self.log_error(f"‚ùó Erreur lors de la mise √† jour du statut de restauration: {str(e)}", e)
            # Tentative de sauvegarde avec moins de champs
            try:
                restore_history.save(update_fields=['status', 'completed_at', 'duration_seconds'])
                self.log_info(f"‚úÖ Restauration ID {restore_history.id} termin√©e - mise √† jour partielle r√©ussie")
            except Exception as e2:
                self.log_error(f"‚ùå √âchec critique de mise √† jour du statut: {str(e2)}", e2)
        
        self.log_info(f"‚úÖ Restauration termin√©e en {duration}s")
    
    def _handle_restore_failure(self, restore_history: RestoreHistory, error: Exception) -> None:
        """G√®re l'√©chec de la restauration"""
        restore_history.status = 'failed'
        restore_history.completed_at = timezone.now()
        restore_history.error_message = str(error)
        restore_history.log_data = self.get_logs_summary()
        
        try:
            restore_history.save()
            self.log_info(f"‚ùå Restauration ID {restore_history.id} marqu√©e comme √©chou√©e")
        except Exception as e:
            self.log_error(f"‚ùó Erreur lors de la mise √† jour du statut d'√©chec: {str(e)}", e)
            # Tentative de sauvegarde avec moins de champs
            try:
                restore_history.save(update_fields=['status', 'completed_at', 'error_message'])
                self.log_info(f"‚ùå Restauration ID {restore_history.id} marqu√©e comme √©chou√©e (mise √† jour partielle)")
            except Exception as e2:
                self.log_error(f"‚ùå √âchec critique de mise √† jour du statut d'√©chec: {str(e2)}", e2)
        
        self.log_error("‚ùå √âchec de la restauration", error)
    
    def _cleanup_after_restore(self, work_dir: Path) -> None:
        """Effectue le nettoyage apr√®s la restauration"""
        self._cleanup_restore_directory(work_dir)
        self._auto_cleanup_temp_files()
    
    def _create_restore_directory(self, restore_name: str) -> Path:
        """Cr√©e le r√©pertoire de travail pour la restauration"""
        restore_dir = self.ensure_backup_directory() / "restore_temp" / restore_name
        restore_dir.mkdir(parents=True, exist_ok=True)
        return restore_dir
    
    def _restore_metadata(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les m√©tadonn√©es Django"""
        self.log_info("üìã Phase 1: Restauration des m√©tadonn√©es")
        
        metadata_file = extract_dir / self.METADATA_FILENAME
        if not metadata_file.exists():
            self.log_warning("‚ö†Ô∏è Fichier de m√©tadonn√©es introuvable")
            return {'records_restored': 0, 'tables_restored': 0, 'metadata_restored': 0}
        
        # Options de restauration des m√©tadonn√©es
        metadata_options = {
            'flush_before': restore_options.get('flush_metadata', False),
            'ignore_duplicates': restore_options.get('ignore_duplicates', True)
        }
        
        try:
            stats = self.metadata_service.import_metadata(metadata_file, metadata_options)
            
            if stats.get('success', True):
                self.log_info(f"‚úÖ M√©tadonn√©es restaur√©es: {stats['records_imported']} enregistrements")
                return {
                    'records_restored': stats['records_imported'],
                    'tables_restored': stats['models_imported'],
                    'metadata_restored': stats['records_imported']
                }
            else:
                error_msg = stats.get('error', 'Erreur inconnue')
                self.log_warning(f"‚ö†Ô∏è Import des m√©tadonn√©es √©chou√©: {error_msg}")
                
                return {
                    'records_restored': 0,
                    'tables_restored': 0, 
                    'metadata_restored': 0,
                    'metadata_error': error_msg
                }
        
        except Exception as e:
            self.log_warning(f"‚ö†Ô∏è Erreur lors de la restauration des m√©tadonn√©es: {str(e)}")
            self.log_info("üìù Poursuite de la restauration sans les m√©tadonn√©es")
            
            return {
                'records_restored': 0,
                'tables_restored': 0,
                'metadata_restored': 0,
                'metadata_error': str(e)
            }
    
    def _restore_database_data(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les donn√©es de la base de donn√©es"""
        self.log_info("üóÑÔ∏è Phase 2: Restauration des donn√©es SQL")
        
        db_settings = settings.DATABASES['default']
        engine = db_settings['ENGINE']
        
        try:
            if 'sqlite3' in engine:
                return self._restore_sqlite(extract_dir, db_settings, restore_options)
            elif 'postgresql' in engine:
                return self._restore_postgresql(extract_dir, db_settings, restore_options)
            elif 'mysql' in engine:
                return self._restore_mysql(extract_dir, db_settings, restore_options)
            else:
                self.log_warning(f"‚ö†Ô∏è Moteur de DB non support√© pour restauration: {engine}")
                return {'data_restored': 0}
                
        except Exception as e:
            raise DatabaseRestoreError(f"Erreur lors de la restauration de la base {engine}: {e}")
    
    def _restore_sqlite(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration sp√©cifique pour SQLite avec gestion s√©curis√©e des contraintes"""
        # V√©rifier la disponibilit√© du fichier SQL de donn√©es
        backup_sql_file = extract_dir / self.DATABASE_DUMP_FILENAME
        backup_db_file = extract_dir / self.DATABASE_SQLITE_FILENAME
        
        # Prioriser le fichier SQL s'il existe (plus s√ªr pour la restauration)
        if backup_sql_file.exists():
            return self._restore_sqlite_from_sql(backup_sql_file, db_settings, restore_options)
        elif backup_db_file.exists():
            return self._restore_sqlite_from_db(backup_db_file, db_settings, restore_options)
        else:
            self.log_warning("‚ö†Ô∏è Aucun fichier SQLite de sauvegarde trouv√©")
            return {'data_restored': 0}
    
    def _restore_sqlite_from_sql(self, sql_file: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration SQLite s√©curis√©e depuis un fichier SQL avec gestion avanc√©e des contraintes FK"""
        current_db_path = Path(db_settings['NAME'])
        
        try:
            # Connexion √† la base de donn√©es actuelle
            conn = sqlite3.connect(str(current_db_path))
            cursor = conn.cursor()
            
            # Diagnostic et pr√©paration
            fk_enabled = self._prepare_sqlite_restore(cursor)
            
            # Ex√©cuter la restauration dans une transaction
            stats = self._execute_sqlite_restore_transaction(cursor, sql_file, restore_options, fk_enabled)
            
            conn.close()
            
            self._log_sqlite_restore_summary(stats)
            
            return {
                'data_restored': stats['executed_statements'],
                'total_statements': stats['total_statements'],
                'failed_statements': stats['failed_statements'],
                'fk_violations': stats['fk_violations'],
                'success_rate': stats['success_rate']
            }
            
        except Exception as e:
            # En cas d'erreur, nettoyer et relancer
            self._cleanup_sqlite_connection(cursor, conn, fk_enabled)
            raise DatabaseRestoreError(f"Erreur lors de la restauration SQLite: {str(e)}")
    
    def _prepare_sqlite_restore(self, cursor) -> bool:
        """Pr√©pare la base SQLite pour la restauration"""
        self.log_info("üîç Analyse du fichier SQL et pr√©paration...")
        
        # V√©rifier l'int√©grit√© avant restauration
        cursor.execute("PRAGMA integrity_check")
        initial_integrity = cursor.fetchone()[0]
        self.log_info(f"üìã Int√©grit√© initiale: {initial_integrity}")
        
        # Sauvegarder l'√©tat des contraintes FK
        cursor.execute("PRAGMA foreign_keys")
        fk_enabled = cursor.fetchone()[0]
        self.log_info(f"üîó Contraintes FK initialement: {'activ√©es' if fk_enabled else 'd√©sactiv√©es'}")
        
        # D√©sactiver temporairement les contraintes FK
        cursor.execute("PRAGMA foreign_keys = OFF")
        cursor.execute("PRAGMA defer_foreign_keys = ON")
        self.log_info("üîì Contraintes FK temporairement d√©sactiv√©es")
        
        return bool(fk_enabled)
    
    def _execute_sqlite_restore_transaction(self, cursor, sql_file: Path, restore_options: Dict[str, Any], fk_enabled: bool) -> Dict[str, Any]:
        """Ex√©cute la restauration SQLite dans une transaction"""
        # Commencer une transaction d√©f√©r√©e
        cursor.execute("BEGIN DEFERRED TRANSACTION")
        
        # Optionnellement vider les tables si demand√©
        if restore_options.get('flush_before', False):
            self._flush_sqlite_tables(cursor)
        
        # Pr√©processer et ex√©cuter le script SQL
        stats = self._execute_sql_statements(cursor, sql_file, restore_options)
        
        # V√©rifier les contraintes avant commit
        fk_violations = self._check_sqlite_constraints(cursor, restore_options)
        stats['fk_violations'] = len(fk_violations)
        
        # Valider la transaction
        cursor.execute("COMMIT")
        self.log_info("‚úÖ Transaction valid√©e avec succ√®s")
        
        # Restaurer l'√©tat des contraintes
        cursor.execute(f"PRAGMA foreign_keys = {'ON' if fk_enabled else 'OFF'}")
        cursor.execute("PRAGMA defer_foreign_keys = OFF")
        
        # V√©rification finale d'int√©grit√©
        self._verify_sqlite_integrity(cursor)
        
        return stats
    
    def _flush_sqlite_tables(self, cursor) -> None:
        """Vide les tables SQLite existantes"""
        self.log_info("üóëÔ∏è Suppression des donn√©es existantes...")
        
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' 
            AND name NOT LIKE 'sqlite_%' 
            AND name NOT IN ('django_migrations', 'auth_permission', 'django_content_type')
            ORDER BY name
        """)
        tables = cursor.fetchall()
        
        for table in tables:
            table_name = table[0]
            try:
                cursor.execute(f"DELETE FROM {table_name}")
                self.log_debug(f"  ‚úÖ Table {table_name} vid√©e")
            except sqlite3.Error as e:
                self.log_warning(f"  ‚ö†Ô∏è Impossible de vider {table_name}: {e}")
    
    def _execute_sql_statements(self, cursor, sql_file: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Ex√©cute les statements SQL avec gestion intelligente des erreurs"""
        self.log_info("üì• Import des donn√©es SQL avec gestion intelligente des erreurs...")
        
        with open(sql_file, 'r', encoding='utf-8') as f:
            sql_content = f.read()
        
        statements = self._parse_sql_statements(sql_content)
        
        # Filtrer les statements pour les uploads (exclure les tables syst√®me)
        if restore_options.get('upload_source', False):
            original_count = len(statements)
            statements = self._filter_system_tables(statements)
            self.log_info(f"üõ°Ô∏è UPLOAD D√âTECT√â - EXCLUSION DES TABLES SYST√àME")
            self.log_info(f"üõ°Ô∏è Statements filtr√©s: {original_count} -> {len(statements)}")
            print(f"üõ°Ô∏è UPLOAD D√âTECT√â - EXCLUSION DES TABLES SYST√àME")  # Log visible dans la console
            print(f"üõ°Ô∏è Statements filtr√©s: {original_count} -> {len(statements)}")
        else:
            print(f"‚ö™ PAS D'UPLOAD D√âTECT√â - upload_source={restore_options.get('upload_source')}")
        
        executed_statements = 0
        failed_statements = []
        deferred_statements = []
        
        # Premier passage: ex√©cuter les statements non probl√©matiques
        for i, statement in enumerate(statements):
            statement = statement.strip()
            if not statement or statement.startswith('--'):
                continue
            
            try:
                cursor.execute(statement)
                executed_statements += 1
            except sqlite3.Error as e:
                if self._handle_sql_error(cursor, e, statement, i, restore_options, deferred_statements, failed_statements):
                    executed_statements += 1
        
        # Deuxi√®me passage: retry des statements diff√©r√©s
        executed_statements += self._retry_deferred_statements(cursor, deferred_statements, failed_statements)
        
        success_rate = executed_statements / len(statements) * 100 if statements else 0
        
        return {
            'executed_statements': executed_statements,
            'total_statements': len(statements),
            'failed_statements': len(failed_statements),
            'success_rate': success_rate
        }
    
    def _handle_sql_error(self, cursor, error: sqlite3.Error, statement: str, line_num: int, restore_options: Dict[str, Any], 
                         deferred_statements: List[Tuple[str, int]], failed_statements: List[Tuple[str, str, int]]) -> bool:
        """G√®re les erreurs SQL de mani√®re intelligente"""
        error_msg = str(error)
        
        if "UNIQUE constraint failed" in error_msg:
            if restore_options.get('ignore_duplicates', True):
                self.log_debug(f"‚ö†Ô∏è Doublon ignor√©: {error_msg}")
                return False
        elif "FOREIGN KEY constraint failed" in error_msg:
            deferred_statements.append((statement, line_num))
            self.log_debug(f"üîÑ Statement diff√©r√© pour FK: ligne {line_num}")
            return False
        elif "NOT NULL constraint failed" in error_msg:
            corrected_statement = self._fix_not_null_statement(statement, error_msg)
            if corrected_statement != statement:
                try:
                    cursor.execute(corrected_statement)
                    self.log_info("üîß Statement corrig√© pour NOT NULL")
                    return True
                except sqlite3.Error:
                    pass
            deferred_statements.append((statement, line_num))
            return False
        
        # Autres erreurs: logger et continuer
        failed_statements.append((statement, error_msg, line_num))
        self.log_warning(f"‚ö†Ô∏è Erreur SQL ligne {line_num}: {error_msg}")
        return False
    
    def _retry_deferred_statements(self, cursor, deferred_statements: List[Tuple[str, int]], 
                                 failed_statements: List[Tuple[str, str, int]]) -> int:
        """Retry des statements diff√©r√©s avec logique d'attente"""
        if not deferred_statements:
            return 0
        
        self.log_info(f"üîÑ Retry de {len(deferred_statements)} statements diff√©r√©s...")
        
        executed_count = 0
        retry_count = 0
        
        while deferred_statements and retry_count < self.MAX_SQL_RETRIES:
            retry_count += 1
            remaining_statements = []
            
            for statement, line_num in deferred_statements:
                try:
                    cursor.execute(statement)
                    executed_count += 1
                    self.log_debug(f"‚úÖ Statement retry r√©ussi: ligne {line_num}")
                except sqlite3.Error as e:
                    remaining_statements.append((statement, line_num))
                    if retry_count == self.MAX_SQL_RETRIES:
                        failed_statements.append((statement, str(e), line_num))
            
            deferred_statements = remaining_statements
            
            if remaining_statements:
                self.log_info(f"üîÑ Retry {retry_count}/{self.MAX_SQL_RETRIES}: {len(remaining_statements)} statements restants")
        
        return executed_count
    
    def _check_sqlite_constraints(self, cursor, restore_options: Dict[str, Any]) -> List[Tuple]:
        """V√©rifie les contraintes SQLite avant commit"""
        self.log_info("üîç V√©rification des contraintes avant commit...")
        
        # R√©activer temporairement les FK pour v√©rifier
        cursor.execute("PRAGMA foreign_keys = ON")
        cursor.execute("PRAGMA foreign_key_check")
        fk_violations = cursor.fetchall()
        
        if fk_violations:
            self.log_warning(f"‚ö†Ô∏è {len(fk_violations)} violations de FK d√©tect√©es:")
            for violation in fk_violations[:5]:  # Afficher seulement les 5 premi√®res
                self.log_warning(f"  - Table: {violation[0]}, FK: {violation[3]}")
            
            if not restore_options.get('ignore_fk_violations', True):
                raise DatabaseRestoreError(f"Violations de contraintes FK d√©tect√©es: {len(fk_violations)}")
            else:
                self.log_info("üîß Violations FK ignor√©es selon les options")
        
        return fk_violations
    
    def _verify_sqlite_integrity(self, cursor) -> None:
        """V√©rifie l'int√©grit√© finale de la base SQLite"""
        cursor.execute("PRAGMA integrity_check")
        final_integrity = cursor.fetchone()[0]
        
        if final_integrity == "ok":
            self.log_info("‚úÖ V√©rification d'int√©grit√© finale r√©ussie")
        else:
            self.log_warning(f"‚ö†Ô∏è Probl√®me d'int√©grit√© finale: {final_integrity}")
    
    def _log_sqlite_restore_summary(self, stats: Dict[str, Any]) -> None:
        """Log le r√©sum√© de la restauration SQLite"""
        self.log_info("‚úÖ Base SQLite restaur√©e:")
        self.log_info(f"  üìä {stats['executed_statements']}/{stats['total_statements']} statements ex√©cut√©es ({stats['success_rate']:.1f}%)")
        self.log_info(f"  ‚ùå {stats['failed_statements']} statements √©chou√©es")
        self.log_info(f"  üîó {stats['fk_violations']} violations FK d√©tect√©es")
    
    def _cleanup_sqlite_connection(self, cursor, conn, fk_enabled: bool) -> None:
        """Nettoie la connexion SQLite en cas d'erreur"""
        try:
            cursor.execute("ROLLBACK")
            cursor.execute(f"PRAGMA foreign_keys = {'ON' if fk_enabled else 'OFF'}")
            cursor.execute("PRAGMA defer_foreign_keys = OFF")
            conn.close()
        except Exception:
            pass
    
    def _parse_sql_statements(self, sql_content: str) -> List[str]:
        """Parse les statements SQL de mani√®re intelligente en g√©rant les statements multi-lignes"""
        # Supprimer les commentaires
        sql_content = re.sub(r'--.*$', '', sql_content, flags=re.MULTILINE)
        
        # S√©parer par ';' mais en tenant compte des strings
        statements = []
        current_statement = ""
        in_string = False
        string_char = None
        
        i = 0
        while i < len(sql_content):
            char = sql_content[i]
            
            if not in_string:
                if char in ['"', "'"]:
                    in_string = True
                    string_char = char
                elif char == ';':
                    statements.append(current_statement.strip())
                    current_statement = ""
                    i += 1
                    continue
            else:
                if char == string_char and (i == 0 or sql_content[i-1] != '\\'):
                    in_string = False
                    string_char = None
            
            current_statement += char
            i += 1
        
        # Ajouter le dernier statement s'il existe
        if current_statement.strip():
            statements.append(current_statement.strip())
        
        return statements
    
    def _filter_system_tables(self, statements: List[str]) -> List[str]:
        """Filtre les statements pour exclure les tables syst√®me lors d'un upload"""
        # Tables syst√®me √† exclure lors d'un upload
        system_tables = [
            'backup_manager_backuphistory',
            'backup_manager_restorehistory',
            'backup_manager_backupconfiguration'
        ]
        
        filtered_statements = []
        excluded_count = 0
        
        for statement in statements:
            statement_upper = statement.upper()
            should_exclude = False
            
            # V√©rifier si le statement concerne une table syst√®me
            for table in system_tables:
                if any(pattern in statement_upper for pattern in [
                    f'INSERT INTO "{table.upper()}"',
                    f'INSERT INTO {table.upper()}',
                    f'UPDATE "{table.upper()}"',
                    f'UPDATE {table.upper()}',
                    f'DELETE FROM "{table.upper()}"',
                    f'DELETE FROM {table.upper()}',
                    f'DROP TABLE "{table.upper()}"',
                    f'DROP TABLE {table.upper()}',
                    f'CREATE TABLE "{table.upper()}"',
                    f'CREATE TABLE {table.upper()}'
                ]):
                    should_exclude = True
                    break
            
            if should_exclude:
                excluded_count += 1
                self.log_debug(f"üö´ Statement exclu (table syst√®me): {statement[:50]}...")
            else:
                filtered_statements.append(statement)
        
        if excluded_count > 0:
            self.log_info(f"üõ°Ô∏è {excluded_count} statements de tables syst√®me exclus pour pr√©server l'historique")
        
        return filtered_statements
    
    def _fix_not_null_statement(self, statement: str, error_msg: str) -> str:
        """Tente de corriger un statement qui viole une contrainte NOT NULL"""
        # Extraire le nom de la colonne de l'erreur
        match = re.search(r'NOT NULL constraint failed: (\w+)\.(\w+)', error_msg)
        if not match:
            return statement
        
        table_name, column_name = match.groups()
        
        # Si c'est un INSERT, tenter d'ajouter une valeur par d√©faut
        if statement.upper().startswith('INSERT') and column_name in self.DEFAULT_NOT_NULL_VALUES:
            self.log_info(f"üîß Tentative de correction NOT NULL pour {table_name}.{column_name}")
            # Cette logique pourrait √™tre am√©lior√©e selon les besoins
        
        return statement
    
    def _restore_sqlite_from_db(self, backup_db_file: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration SQLite depuis un fichier de base de donn√©es (m√©thode de remplacement - moins s√ªre)"""
        current_db_path = Path(db_settings['NAME'])
        
        # Sauvegarde de la DB actuelle si demand√© - D√âSACTIV√â TEMPORAIREMENT
        # if restore_options.get('backup_current', True):
        #     self._backup_current_database(current_db_path)
        
        # Avertissement sur cette m√©thode
        self.log_warning("‚ö†Ô∏è Utilisation de la m√©thode de remplacement de DB (moins s√ªre)")
        
        # Remplacement de la base de donn√©es
        if current_db_path.exists():
            current_db_path.unlink()
        
        shutil.copy2(backup_db_file, current_db_path)
        
        file_size = current_db_path.stat().st_size
        self.log_info(f"‚úÖ Base SQLite restaur√©e par remplacement: {self.format_size(file_size)}")
        
        # IMPORTANT: Marquer que la DB a √©t√© compl√®tement remplac√©e
        return {
            'data_restored': 1, 
            'database_replaced': True  # Nouvelle cl√© pour indiquer le remplacement complet
        }
    
    def _backup_current_database(self, current_db_path: Path) -> None:
        """Sauvegarde la base de donn√©es actuelle"""
        backup_current_path = current_db_path.with_suffix(f'.backup_{timezone.now().strftime("%Y%m%d_%H%M%S")}.sqlite3')
        if current_db_path.exists():
            shutil.copy2(current_db_path, backup_current_path)
            self.log_info(f"üíæ DB actuelle sauvegard√©e: {backup_current_path}")
    
    def _restore_postgresql(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration sp√©cifique pour PostgreSQL"""
        dump_file = extract_dir / self.DATABASE_DUMP_FILENAME
        if not dump_file.exists():
            self.log_warning("‚ö†Ô∏è Dump PostgreSQL introuvable")
            return {'data_restored': 0}
        
        # Drop et recr√©ation de la DB si demand√©
        # Note: La sauvegarde automatique est d√©sactiv√©e temporairement
        if restore_options.get('drop_before_restore', False):
            # Pas de sauvegarde automatique avant le drop
            self._drop_postgresql_database(db_settings)
            self._create_postgresql_database(db_settings)
        
        # Restauration avec psql
        cmd = [
            'psql',
            f"--host={db_settings.get('HOST', 'localhost')}",
            f"--port={db_settings.get('PORT', 5432)}",
            f"--username={db_settings['USER']}",
            f"--dbname={db_settings['NAME']}",
            '--quiet',
            f"--file={dump_file}"
        ]
        
        env = {'PGPASSWORD': db_settings.get('PASSWORD', '')} if db_settings.get('PASSWORD') else {}
        
        try:
            result = subprocess.run(cmd, env=env, capture_output=True, text=True, timeout=3600)
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, cmd, result.stderr)
            
            self.log_info("‚úÖ Base PostgreSQL restaur√©e")
            return {'data_restored': 1}
            
        except subprocess.CalledProcessError as e:
            raise DatabaseRestoreError(f"Erreur psql: {e.stderr}")
        except subprocess.TimeoutExpired:
            raise DatabaseRestoreError("Timeout lors de la restauration PostgreSQL")
    
    def _restore_mysql(self, extract_dir: Path, db_settings: Dict[str, Any], restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restauration sp√©cifique pour MySQL"""
        # Param√®tre restore_options disponible pour futures options
        # Note: La sauvegarde automatique est d√©sactiv√©e temporairement
        _ = restore_options  # Marquer comme intentionnellement inutilis√©
        
        dump_file = extract_dir / self.DATABASE_DUMP_FILENAME
        if not dump_file.exists():
            self.log_warning("‚ö†Ô∏è Dump MySQL introuvable")
            return {'data_restored': 0}
        
        # Pas de sauvegarde automatique avant la restauration
        
        cmd = [
            'mysql',
            f"--host={db_settings.get('HOST', 'localhost')}",
            f"--port={db_settings.get('PORT', 3306)}",
            f"--user={db_settings['USER']}",
            f"--password={db_settings.get('PASSWORD', '')}",
            db_settings['NAME']
        ]
        
        try:
            with open(dump_file, 'r') as f:
                result = subprocess.run(cmd, stdin=f, capture_output=True, text=True, timeout=3600)
            
            if result.returncode != 0:
                raise subprocess.CalledProcessError(result.returncode, cmd, result.stderr)
            
            self.log_info("‚úÖ Base MySQL restaur√©e")
            return {'data_restored': 1}
            
        except subprocess.CalledProcessError as e:
            raise DatabaseRestoreError(f"Erreur mysql: {e.stderr}")
        except subprocess.TimeoutExpired:
            raise DatabaseRestoreError("Timeout lors de la restauration MySQL")
    
    def _restore_files(self, extract_dir: Path, restore_options: Dict[str, Any]) -> Dict[str, Any]:
        """Restaure les fichiers syst√®me"""
        self.log_info("üìÅ Phase 3: Restauration des fichiers")
        
        files_dir = extract_dir / self.FILES_DIRNAME
        if not files_dir.exists():
            self.log_warning("‚ö†Ô∏è R√©pertoire de fichiers introuvable")
            return {'files_restored': 0}
        
        try:
            files_restored = 0
            
            # PROTECTION: Ne pas restaurer les fichiers media lors d'un upload
            # pour √©viter de supprimer les sauvegardes existantes
            if not restore_options.get('upload_source', False):
                # Restauration des fichiers media seulement pour les restaurations normales
                files_restored += self._restore_media_files(files_dir, restore_options)
            else:
                self.log_info("üõ°Ô∏è Upload d√©tect√© - restauration des fichiers media ignor√©e pour pr√©server les sauvegardes")
            
            # Restauration des logs (toujours autoris√©e)
            files_restored += self._restore_log_files(files_dir, restore_options)
            
            self.log_info(f"‚úÖ {files_restored} fichiers restaur√©s")
            return {'files_restored': files_restored}
            
        except Exception as e:
            raise FileRestoreError(f"Erreur lors de la restauration des fichiers: {e}")
    
    def _restore_media_files(self, files_dir: Path, restore_options: Dict[str, Any]) -> int:
        """Restaure les fichiers media"""
        media_source = files_dir / "media"
        if not (media_source.exists() and hasattr(settings, 'MEDIA_ROOT')):
            return 0
        
        media_dest = Path(settings.MEDIA_ROOT)
        
        # Sauvegarde des fichiers media actuels - D√âSACTIV√â TEMPORAIREMENT
        # if restore_options.get('backup_current_files', True):
        #     self._backup_current_media_files(media_dest)
        
        # Restauration
        if media_dest.exists():
            shutil.rmtree(media_dest)
        shutil.copytree(media_source, media_dest, dirs_exist_ok=True)
        
        files_count = sum(1 for _ in media_dest.rglob('*') if _.is_file())
        self.log_info(f"üì∑ Fichiers media restaur√©s: {media_dest}")
        
        return files_count
    
    def _backup_current_media_files(self, media_dest: Path) -> None:
        """Sauvegarde les fichiers media actuels"""
        backup_media_path = media_dest.parent / f"media_backup_{timezone.now().strftime('%Y%m%d_%H%M%S')}"
        if media_dest.exists():
            shutil.copytree(media_dest, backup_media_path, dirs_exist_ok=True)
            self.log_info(f"üíæ Fichiers media actuels sauvegard√©s: {backup_media_path}")
    
    def _restore_log_files(self, files_dir: Path, restore_options: Dict[str, Any]) -> int:
        """Restaure les fichiers de logs"""
        logs_source = files_dir / "logs"
        if not logs_source.exists():
            return 0
        
        logs_dest = Path('logs')
        
        if restore_options.get('merge_logs', True):
            # Fusion avec les logs existants
            if logs_dest.exists():
                shutil.copytree(logs_source, logs_dest, dirs_exist_ok=True)
            else:
                shutil.copytree(logs_source, logs_dest)
        else:
            # Remplacement complet
            if logs_dest.exists():
                shutil.rmtree(logs_dest)
            shutil.copytree(logs_source, logs_dest)
        
        files_count = sum(1 for _ in logs_dest.rglob('*') if _.is_file())
        self.log_info(f"üìã Logs restaur√©s: {logs_dest}")
        
        return files_count
    
    def _cleanup_restore_directory(self, restore_dir: Path) -> None:
        """Nettoie le r√©pertoire temporaire de restauration"""
        try:
            if restore_dir.exists():
                shutil.rmtree(restore_dir)
                self.log_info(f"üßπ R√©pertoire temporaire nettoy√©: {restore_dir}")
        except Exception as e:
            self.log_warning(f"‚ö†Ô∏è Impossible de nettoyer {restore_dir}: {e}")
    
    def _drop_postgresql_database(self, db_settings: Dict[str, Any]) -> None:
        """Supprime une base PostgreSQL"""
        # Cette fonction n√©cessite des privil√®ges administrateur
        # √Ä impl√©menter selon les besoins sp√©cifiques
        pass
    
    def _create_postgresql_database(self, db_settings: Dict[str, Any]) -> None:
        """Cr√©e une base PostgreSQL"""
        # Cette fonction n√©cessite des privil√®ges administrateur
        # √Ä impl√©menter selon les besoins sp√©cifiques
        pass
    
    def _auto_cleanup_temp_files(self) -> None:
        """Nettoyage automatique des fichiers temporaires anciens"""
        try:
            from .cleanup_service import CleanupService
            
            cleanup_service = CleanupService()
            # Nettoyer les fichiers de plus de 2h automatiquement
            results = cleanup_service.cleanup_all_temporary_files(max_age_hours=self.AUTO_CLEANUP_MAX_AGE_HOURS)
            
            # Log seulement si quelque chose a √©t√© nettoy√©
            if results['totals']['files_deleted'] > 0:
                self.log_info(
                    f"üßπ Nettoyage automatique: "
                    f"{results['totals']['files_deleted']} fichiers temporaires supprim√©s, "
                    f"{cleanup_service.format_size(results['totals']['size_freed'])} lib√©r√©s"
                )
        except Exception as e:
            # Ne pas faire √©chouer la restauration si le nettoyage √©choue
            self.log_warning(f"‚ö†Ô∏è Nettoyage automatique √©chou√©: {e}") 